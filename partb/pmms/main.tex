\documentclass{tikzposter} %Options for format can be included here
\geometry{paperwidth=2250mm, paperheight=2500mm}
\makeatletter
\setlength{\TP@visibletextwidth}{\textwidth-2\TP@innermargin}
\setlength{\TP@visibletextheight}{\textheight-2\TP@innermargin}
\makeatother
\usepackage{amsmath}
% \usepackage{eucal}
\usepackage{mathrsfs}
\usepackage{amssymb}
\usepackage{dsfont}
\usepackage{enumitem}
\usepackage{parskip}
\usepackage{amsfonts}
\usepackage{verbatim}
\usepackage{nicefrac}
\usepackage{xcolor}
\usepackage{mathtools}
\DeclarePairedDelimiter{\floor}{\lfloor}{\rfloor}
\DeclarePairedDelimiter{\ceil}{\lceil}{\rceil}
\DeclareMathOperator{\Int}{int}
\DeclareMathOperator{\cl}{cl}
\DeclareMathOperator{\Var}{Var}
\newcommand\restr[2]{{% we make the whole thing an ordinary symbol
  \left.\kern-\nulldelimiterspace % automatically resize the bar with \right
  #1 % the function
  \vphantom{\big|} % pretend it's a little taller at normal size
  \right|_{#2} % this is the delimiter
  }}
\newcommand\leftopen[2]{\ensuremath{(#1,#2]}}
\newcommand\rightopen[2]{\ensuremath{[#1,#2)}}

\newtheorem{theorem}{Theorem}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}{Corollary}

\newtheorem{definition}{Definition}

\newtheorem{remark}{Remark}
\newtheorem{claim}{Claim}
\newtheorem{case}{Case}

\definecolor{nbYellow}{HTML}{FCF434}
\definecolor{nbPurple}{HTML}{9C59D1}
\definecolor{nbBlack}{HTML}{2C2C2C}
\definecolor{tBlue}{HTML}{5BCEFA}
\definecolor{tPink}{HTML}{F5A9B8}
\definecolor{bp1}{HTML}{D60270}
\definecolor{bp2}{HTML}{9B4F96}
\definecolor{bp3}{HTML}{0038A8}
\definecolor{pcs1}{HTML}{B300B3}
\definecolor{pcs2}{HTML}{54007D}
\definecolor{pcs3}{HTML}{B30086}
\definecolor{pcs4}{HTML}{3C00B3}
\definecolor{pcs5}{HTML}{2A007D}

\definecolorstyle{NewColour} {
  \definecolor{c1}{named}{nbBlack}
  \definecolor{c2}{named}{nbPurple}
  \definecolor{c3}{named}{nbYellow}
}{
  % Background Colors
  \colorlet{backgroundcolor}{black!10}
  \colorlet{framecolor}{black}
  % Title Colors
  \colorlet{titlefgcolor}{black}
  \colorlet{titlebgcolor}{black!10}
  % Block Colors
  \colorlet{blocktitlebgcolor}{c1}
  \colorlet{blocktitlefgcolor}{white}
  \colorlet{blockbodybgcolor}{white}
  \colorlet{blockbodyfgcolor}{black}
  % Innerblock Colors
  \colorlet{innerblocktitlebgcolor}{c2!80}
  \colorlet{innerblocktitlefgcolor}{black}
  \colorlet{innerblockbodybgcolor}{c2!50}
  \colorlet{innerblockbodyfgcolor}{black}
  % Note colors
  \colorlet{notefgcolor}{black}
  \colorlet{notebgcolor}{c3!50}
  \colorlet{notefrcolor}{c3!70}
}

\defineblockstyle{NewBlock}{
  titlewidthscale=1, bodywidthscale=1, titleleft,
  titleoffsetx=0pt, titleoffsety=0pt, bodyoffsetx=0pt, bodyoffsety=0pt,
  bodyverticalshift=0pt, roundedcorners=0, linewidth=0pt, titleinnersep=1cm,
  bodyinnersep=1cm
}{
  \ifBlockHasTitle%
  \draw[draw=none, fill=blocktitlebgcolor]
  (blocktitle.south west) rectangle (blocktitle.north east);
  \fi%
  \draw[draw=none, fill=blockbodybgcolor] %
  (blockbody.north west) [rounded corners=30] -- (blockbody.south west) --
  (blockbody.south east) [rounded corners=0]-- (blockbody.north east) -- cycle;
}

% Choose Layout
\usecolorstyle{NewColour}
\usebackgroundstyle{Default}
\usetitlestyle{Filled}
\useblockstyle{NewBlock}
\useinnerblockstyle[roundedcorners=0.2]{Default}
\usenotestyle[roundedcorners=0]{Default}

\settitle{\centering \color{titlefgcolor} {\Large \@title \, -- \, \@author}}

% Title, Author, Institute
\title{Probability, Measure and Martingales}
\author{Ike Glassbrook}

\begin{document}

% Title block with title, author, logo, etc.
\maketitle[titletoblockverticalspace=0.4cm]
\begin{columns}
  \column{0.2}
  \block{Measurable sets and functions}{
    \begin{definition}[$\sigma$-algebras]
      \ Let $\Omega$ be a set and $\mathcal{A} \subseteq \mathcal{P}(\Omega)$ be a collection of subsets of $\Omega$:
      \begin{enumerate}[label=\roman*.]
              \item $\mathcal{A}$ is an \emph{algebra} if $\varnothing \in \mathcal{A}$ and for $A, B \in \mathcal{A}$, $\mathcal{A}^{c} = \Omega \setminus A \in \mathcal{A}$ and $A \cup B \in \mathcal{A}$.
              \item $\mathcal{A}$ is a \emph{$\sigma$-algebra} if $\varnothing \in \mathcal{A}$, for $A \in \mathcal{A}$, $A^{c} \in \mathcal{A}$, and for $(A_{n})$ a sequence of sets in $\mathcal{A}$, $\bigcup_{n=1}^{\infty} A_{n} \in \mathcal{A}$.
      \end{enumerate}

    \end{definition}
    \hphantom{}

    A collection of sets is an algebra subject to being closed under finite applications of the basic operators. The $\sigma$-algebra concept extends this slightly to infinite ones. Consider where this distinction is relevant? \\

    Note that if we have $\{\mathcal{F}_{i} : i \in I\}$ are $\sigma$-algebras, then
    \begin{align*}
      \mathcal{F} = \bigcap_{i \in I} \mathcal{F}_{i}
    \end{align*}
    is a $\sigma$-algebra. This allows us to consider the notion of a smallest $\sigma$-algebra containing a set (the $\sigma$-algebra `generated' by a set). We write the $\sigma$-algebra generated by a collection of collections of sets $\mathfrak{A}$ as $\sigma(\mathfrak{A})$. \\

    \begin{definition}[Borel $\sigma$-algebra]
    \ Let $(E, \mathcal{T})$ be a topological space. The $\sigma$-algebra generated by the open sets in $E$ is called the \emph{Borel $\sigma$-algebra on $E$} and is denoted $\mathcal{B}(E) = \sigma(\mathcal{T})$.
    \end{definition}
    \hphantom{}

    \begin{definition}
    \ Suppose $(\Omega_{i}, \mathcal{F}_{i})_{i \in I}$ are measurable spaces. With $\Omega = \prod_{i \in I} \Omega_{i}$, $\mathcal{F}$ the $\sigma$-algebra generated by $A = \prod_{i \in I} A_{i}$ where $A_{i} \in \mathcal{F}_{i}$ for all $i \in I$ and for all but finitely many $i \in I$, $A_{i} = \Omega_{i}$: $(\Omega, \mathcal{F})$ is the product space.
    \end{definition}
    \hphantom{}

    This space is measurable, and $\mathcal{F}$ is a $\sigma$-algebra. \\

    \begin{definition}[$\pi$ and $\lambda$-systems]
    \ A collection of sets $\mathcal{A}$ is called a $\pi$-system if it is closed under intersections. \\

      A collection of sets $\mathcal{M}$ is called a $\lambda$-system if $\Omega \in \mathcal{M}$, if $A, B \in \mathcal{M}$, $A \subseteq B$, then $B \setminus A \in \mathcal{M}$, and if $(A_{n}) \subseteq \mathcal{M}$ with $A_{n} \subseteq A_{n+1}$ increasing then $\bigcup_{n \ge 1} A_{n} \in \mathcal{M}$.
    \end{definition}
    \hphantom{}

    A collection of sets is a $\sigma$-algebra if and only if it is both a $\pi$-system and a $\lambda$-system. \\

    \begin{lemma}[$\pi$-$\lambda$ systems lemma]
    \ Let $\mathcal{A}$ be a $\pi$-system and $\mathcal{M}$ a $\lambda$-system. Then if $\mathcal{A} \subseteq \mathcal{M}$ then $\sigma(\mathcal{A}) \subseteq \mathcal{M}$.
    \end{lemma}
    \hphantom{}

    We can use this with a convenient $\pi$-system to show that our $\lambda$-system contains more than is immediately obvious. \\

    Let $\lambda(\mathcal{A})$ be the smallest $\lambda$-system containing $\mathcal{A}$. This is a subset of $\mathcal{M}$ and $\sigma(\mathcal{A})$, so we just need to show that $\lambda(\mathcal{A})$ is a $\sigma$-algebra (for which we just have to show that it is a $\pi$-system). \\

    \begin{definition}[Random variables]
    \ With measurable spaces $(\Omega, \mathcal{F})$, $(E, \mathcal{E})$, a function $f : \Omega \to E$ is said to be an $E$-valued random variable (or a measurable function) if for all $A \in \mathcal{E}$, $f^{-1}(A) \in \mathcal{F}$.
    \end{definition}
    \hphantom{}

    We get immediately that random variables can be composed as one would expect. We can also use random variables to define new $\sigma$-algebras. Note that $(\Omega, \{f^{-1}(A) : A \in \mathcal{E}\})$ is a $\sigma$-algebra. \\

    \begin{definition}
    \ With $\{f_{i} : i \in I\}$ a family of functions $\Omega \to E$, $\sigma(f_{i} : i \in I)$ is the smallest $\sigma$-algebra on $\Omega$ for which all $f_{i}$ are measurable.
    \end{definition}
    \hphantom{}

    This is initially a slightly intimidating definition, but the intuition is just that we need our $\sigma(f_{i} : i \in I) = \sigma(f_{i}^{-1}(A) : A \in \mathcal{E}, i \in I)$. \\

    \begin{theorem}[Monotone Class Theorem]
      \ Let $\mathcal{H}$ be a class of bounded functions from $\Omega \to \mathbb{R}$ such that
      \begin{itemize}
              \item \ $\mathcal{H}$ is a vector space over $\mathbb{R}$,
              \item \ the constant function $1 \in \mathcal{H}$,
              \item \ if $(f_{n}) \subseteq \mathcal{H}$, $f_{n} \to f$ monotonically increasing, then $f \in \mathcal{H}$,
      \end{itemize}
      then if $\mathcal{C} \subseteq \mathcal{H}$, and $\mathcal{C}$ is closed under pointwise multiplication, then all bounded $\sigma(\mathcal{C})$-measurable functions are in $\mathcal{H}$.
    \end{theorem}
    \hphantom{}

    To get an intuition for this, note that any $f \in \mathcal{C}$ is necessarily bounded and $\sigma(\mathcal{C})$-measurable, but the converse is not immediate. Thus we essentially get a statement of the $\lambda$-$\pi$ systems lemma but for functions on analogous systems. \\

    We can firstly see that $\mathcal{H}$ is closed in $\mathcal{F}_{b}(\Omega)$. Then, we can prove the statement for the special case of $\mathcal{C} = \{\chi_{A} : A \in \mathcal{A}\}$ for a $\pi$-system $\mathcal{A}$, then adding $1$ to $\mathcal{C}$ without loss of generality we can make the proof more general (concretely, because $\sigma(\mathcal{C}) \subseteq \sigma(\mathcal{C} \cup \{1\})$). \\

    It may allow this theorem to make more sense to note that $\lambda$-systems are sometimes referred to as `monotone classes'. Thus the $\pi$-$\lambda$ systems lemma can be seen as saying that for $\mathcal{A}$ a $\pi$-system, the (smallest) monotone class generated by $\mathcal{A}$ is $\sigma(\mathcal{A})$. \\

    We can use the monotone class theorem to demonstrate that for $f : \Omega_{1} \times \Omega_{2} \to \mathbb{R}$ is measurable, then fixing $\omega_{1} \in \Omega_{1}$, $\omega_{2} \mapsto f(\omega_{1}, \omega_{2})$ is measurable.
  }
  \block{Conditional Probability}{
    Up until presently, we've considered the notion of event $A$ conditioned on event $B$ as having a fixed probability. This doesn't entirely capture what a conditional is however -- we're conditioning on the amount of information we have, and therefore we want the conditional probability to change as a function of our information. In particular, we want our conditional probability to be a function of $\omega \in \Omega$, and in order to reflect conditioning as a reflection of information, we want to condition over events in a $\sigma$-algebra, rather than individual events. \\

    Doing more algebra, we see that expectation is a more fitting operator, leading us to the following definition:
    \begin{definition}[Conditional expectation]
    \ Let $(\Omega, \mathcal{F}, \mathbb{P})$ be a probability space, $X \in \mathcal{L}^{1}(\Omega, \mathcal{F}, \mathbb{P})$, $\mathcal{G} \subseteq \mathcal{F}$ a $\sigma$-algebra. A random variable $Y \in \mathcal{L}^{1}(\Omega, \mathcal{G}, \mathbb{P})$ is (a version of) the conditional expectation of $X$ given $\mathcal{G}$ if for $G \in \mathcal{G}$,
    \begin{align*}
      \mathbb{E}\big[Y \chi_{G}\big] = \mathbb{E}\big[X \chi_{G}\big].
    \end{align*}
    \end{definition}
    The key aspect of this statement can be rewritten as
    \begin{align*}
      \int_{G} \mathbb{E}\big[X \,|\, \mathcal{G}\big] \, \mathrm{d}\mathbb{P} = \int_{G} X \, \mathrm{d}\mathbb{P},
    \end{align*}
    which allows us to carry over all of our normal integration properties to conditional expectations. \\

    \begin{theorem}
    \ The conditional expectation of $X$ given $\mathcal{G}$ exists, denoted $\mathbb{E}\big[X \,|\, \mathcal{G}\big]$, and if $Z$ is also the conditional expectation of $X$ given $\mathcal{G}$, then
    \begin{align*}
      Z = \mathbb{E}\big[X \,|\, \mathcal{G}\big] \,\,\, \text{a.s.}
    \end{align*}
    \end{theorem}

    \textbf{Come back to the proof of this.} \\

    Note importantly how conditional expectations behave with respect to measurability. If we have $X$ a $\mathcal{G}$-measurable random variable, then
    \begin{align*}
      \mathbb{E}\big[X \,|\, \mathcal{G}\big] \overset{\mathrm{a.s.}}{=} X.
    \end{align*}
    Meanwhile if $\sigma(X)$ and $\mathcal{G}$ are independent, then
    \begin{align*}
      \mathbb{E}\big[X \,|\, \mathcal{G}\big] \overset{\mathrm{a.s.}}{=} \mathbb{E}\big[X\big].
    \end{align*}
    \hphantom{}

    \begin{lemma}[Tower property]
      \ Take $X \in \mathcal{L}^{1}(\Omega, \mathcal{F}, \mathbb{P})$, $\mathcal{F}_{1}$, $\mathcal{F}_{2}$ both $\sigma$-algebras, satisfying $\mathcal{F}_{1} \subseteq \mathcal{F}_{2} \subseteq \mathcal{F}$. Then
      \begin{align*}
        \mathbb{E}\Big[\mathbb{E}\big[X \,|\, \mathcal{F}_{2}\big] \,|\, \mathcal{F}_{1}\Big] \overset{\mathrm{a.s.}}{=} \mathbb{E}\big[X \,|\, \mathcal{F}_{1}\big].
      \end{align*}
    \end{lemma}

    This should be relatively intuitive -- $\mathbb{E}\big[X \,|\, \mathcal{F}_{2}\big]$ contains more information than can be represented in $\mathcal{F}_{1}$, but is fundamentally still expressing a reduced form of $X$, which can be reduced more to give $\mathbb{E}\big[X \,|\, \mathcal{F}_{1}\big]$. \\

    One can also consider this as a commutativity statement: as $\mathbb{E}\big[X \,|\, \mathcal{F}_{1}\big]$ is $\mathcal{F}_{2}$-measurable, thus $\mathbb{E}\big[X \,|\, \mathcal{F}_{1}\big] = \mathbb{E}\big[\mathbb{E}[X \,|\, \mathcal{F}_{1}] \,|\, \mathcal{F}_{2}\big]$, so the tower property is stating that with $\mathcal{F}_{1} \subseteq \mathcal{F}_{2}$:
    \begin{align*}
      \mathbb{E}\Big[\mathbb{E}\big[X \,|\, \mathcal{F}_{1}\big] \,|\, \mathcal{F}_{2}\Big] \overset{\mathrm{a.s.}}{=} \mathbb{E}\Big[\mathbb{E}\big[X \,|\, \mathcal{F}_{2}\big] \,|\, \mathcal{F}_{1}\Big].
    \end{align*}
    \coloredbox{
    I'm tempted to claim the more general statement, that for $\mathcal{F}_{1}$, $\mathcal{F}_{2}$ both $\sigma$-algebras in $\mathcal{F}$:
    \begin{align*}
      \color{red}
      \mathbb{E}\Big[\mathbb{E}\big[X \,|\, \mathcal{F}_{1}\big] \,|\, \mathcal{F}_{2}\Big] \overset{\mathrm{a.s.}}{=} \mathbb{E}\big[X \,|\, \mathcal{F}_{1} \cap \mathcal{F}_{2}\big].
    \end{align*}
    This statement is true if $\mathcal{F}_{1}$ and $\mathcal{F}_{2}$ are independent, because then both sides are equal to $\mathbb{E}[X]$, but it seems that there could be a `middle-ground' between independence and containment for which commutativity stops holding. \\

    On the other side, attempting to prove this statement, the tripping point is that it's unclear that the LHS is $\mathcal{F}_{1}$-measurable (although clearly it is $\mathcal{F}_{2}$-measurable).
    }

    \begin{lemma}
    \ Take $X$, $Y$ random variables on $(\Omega, \mathcal{F}, \mathbb{P})$ with $X$, $Y$, and $XY$ integrable. Then
    \begin{align*}
      \mathbb{E}\big[XY \,|\, \sigma(Y)\big] \overset{\mathrm{a.s.}}{=} Y\mathbb{E}\big[X \,|\, \sigma(Y)\big].
    \end{align*}
    \end{lemma}
    Ensure for yourself that it's clear why this implies the same holding for $\mathcal{G} \supseteq \sigma(Y)$ instead of $\sigma(Y)$. \\

    \begin{theorem}
    \ Take $X \in \mathcal{L}^{1}(\Omega, \mathcal{F}, \mathbb{P})$, $\{\mathcal{F}_{i} : i \in I\}$ a family of $\sigma$-algebras in $\mathcal{F}$. Then $\big\{\mathbb{E}\big[X \,|\, \mathcal{F}_{i}\big] : i \in I\big\}$ is uniformly integrable.
    \end{theorem}
    \hphantom{}

    Using conditional expectation, we can introduce an inner product to $\mathcal{L}^{2}$, $\langle X, Y \rangle := \mathbb{E}[XY]$ (`introduce' is probably slightly strong, this inner product already exists for other purposes in functional analysis -- although we usually use the Lebesgue measure). This gives us that $\mathcal{L}^{2}$ is a Hilbert space, and all of the corresponding results.
  }


  \column{0.2}
  \block{Measures on $\mathbb{R}$}{
    \begin{definition}
      \ A measure space is a triple $(\Omega, \mathcal{F}, \mu)$ such that $\Omega$ is a set, $\mathcal{F}$ is a $\sigma$-algebra on $\Omega$, and $\mu : \mathcal{F} \to [0,\infty]$ is countably additive ($\mu$ is then a \emph{measure} on $(\Omega, \mathcal{F})$).
    \end{definition}
    \hphantom{}

    \begin{definition}
    \ Let $\mu$ be a probability measure on $\mathcal{B}(\mathbb{R})$. The distribution function of $\mu$ is $F_{\mu}(x) = \mu\leftopen{-\infty}{x}$, where we require that $F_{\mu}$ is non-decreasing, tends to $0$ as $x \to -\infty$, to $1$ as $x \to \infty$, and is right continuous.
    \end{definition}
    \hphantom{}

    \begin{definition}
    \ We say that $\nu$ is absolutely continuous with respect to $\mu$, $\nu \ll \mu$, if for any $A \in \mathcal{F}$, $\mu(A) = 0$ implies that $\nu(A) = 0$. Further, we say that $\mu$ and $\nu$ are equivalent, $\mu \sim \nu$, if $\mu \ll \nu$ and $\nu \ll \mu$.
    \end{definition}
    \hphantom{}

    \innerblock{Extensions}{
      For the most part, it's difficult to characterise a measure explicitly, due to $\sigma$-algebras being incredibly large in all but countable $\Omega$. We therefore wish to characterise them in terms of their value on algebras. \\

      \begin{theorem}[Uniqueness of extension]
      \ Let $\mu_{1}$ and $\mu_{2}$ be measures on a space $(\Omega, \mathcal{F})$, and $\mathcal{A} \subseteq \mathcal{F}$ is a $\pi$-system with $\sigma(\mathcal{A}) = \mathcal{F}$. Then if $\mu_{1}(\Omega) = \mu_{2}(\Omega) < \infty$ and $\restr{\mu_{1}}{\mathcal{A}} = \restr{\mu_{2}}{\mathcal{A}}$, then $\mu_{1} = \mu_{2}$.
      \end{theorem}
      \hphantom{}

      This follows immediately via the $\lambda$-$\pi$ systems lemma. \\

     \begin{theorem}[Carath\'{e}odory Extension theorem]
    \ Let $\Omega$ be a set and $\mathcal{A}$ an algebra on $\Omega$, then with $\mu_{0} : \mathcal{A} \to [0,\infty]$ a countably additive set function, there exists a measure $\mu : \sigma(\mathcal{A}) \to [0,\infty]$ such that $\restr{\mu}{\mathcal{A}} = \mu_{0}$.
    \end{theorem}
    \hphantom{}

    One can derive this from defining the outer measure $\mu^{*}$ in terms of $\mu_{0}$, and claiming that a set is measurable iff for all $E \subseteq \Omega$, $\mu^{*}(E) = \mu^{*}(E \cap B) + \mu^{*}(E \setminus B)$. We can then prove that this gives the smallest $\sigma$-algebra containing $\mathcal{A}$.
    }
    \hphantom{}

    \begin{definition}[Distribution function]
    \ If a function $F : \mathbb{R} \to [0,1]$ satisfies:
    \begin{enumerate}[label=\roman*.]
          \item \ $F$ is non-decreasing;
          \item \ $F(x) \to 0$ as $x \to -\infty$, $F(x) \to 1$ as $x \to \infty$; and
            \item \ $F$ is continuous from the right,
    \end{enumerate}
    then $F$ is a distribution function.
    \end{definition}
    \hphantom{}

    \begin{theorem}
    \ Let $F$ be a distribution function. Then there exists a unique Borel probability measure $\mu$ on $\mathbb{R}$ such that $\mu\leftopen{-\infty}{x} = F(x)$. Further, every Borel probability measure on $\mathbb{R}$ defines a distribution function.
    \end{theorem}
    \hphantom{}

    A corollary of this is that there is a unique Borel measure such that for all $a < b \in \mathbb{R}$, $\mu\leftopen{a}{b} = b-a$. \\

    This result demonstrates that there is a bijection between measures on $(\mathbb{R}, \mathcal{B}(\mathbb{R}))$ and distribution functions. In particular, we call these measures the Lebesgue-Stieltjes measures. \\

    The proof of this theorem follows using both of the extension theorems. In particular, we use the algebra of left open right closed intervals. \\

    \begin{definition}[Pushforward measure]
      \ Let $(\Omega, \mathcal{F}, \mathbb{P})$ be a probability space, $X : \Omega \to E$, then for $A \in \mathcal{E}$,
      \begin{align*}
        \mathbb{Q}(E) := \mathbb{P}(X^{-1}(E))
      \end{align*}
    \end{definition}
    \hphantom{}

    Thus we have a (very non-injective) map from random variables in $E$ to probability measures on $E$. This is useful, on the basis that many properties of random variables will just be properties of the pushforward measure rather than the random variable itself. \\

    \begin{theorem}
      \ For $\{(\Omega_{i}, \mathcal{F}_{i}, \mathbb{P}_{i}) : i \in \{1, \dots, n\}\}$ a set of probability measures, there is a unique measure $\mathbb{P}$ on $\displaystyle \left(\prod_{i=1}^{n} \Omega_{i},\bigtimes_{i=1}^{n} \mathcal{F}_{i}\right)$ such that for $E_{i} \in \mathcal{F}_{i}$ with $i \in \{1,\dots,n\}$,
      \begin{align*}
        \mathbb{P}\left(\prod_{i=1}^{n} E_{i}\right) &= \prod_{i=1}^{n} \mathbb{P}_{i}(E_{i}).
      \end{align*}

    \end{theorem}
    \hphantom{}

    It's hopefully natural here that one should aim an induction proof. \\

    The theorem here then allows us to extend the matter to infinite products, although at this point we require that what we're dealing with are probability measures (to keep each term in $[0,1]$ for convergence reasons), rather than just finite measures as could work with the previous statement of the theorem.
  }
  \block{Independence}{
    \begin{definition}[Independence]
      \ With $(\Omega, \mathcal{F}, \mathbb{P})$ a probability space, $(\mathcal{G}_{i})_{i=1}^{n}$ a collection of $\sigma$-algebras, these $\sigma$-algebras are independent if for $E_{i} \in \mathcal{G}_{i}$ for $i \in \{1,\dots,n\}$
      \begin{align*}
        \mathbb{P}\left(\bigcap_{i=1}^{n} E_{i}\right) &= \prod_{i=1}^{n} \mathbb{P}(E_{i}).
      \end{align*}
      Further, an arbitrary collection $(G_{i})_{i \in I}$ of $\sigma$-algebras is independent if any finite subset of the collection is independent.
    \end{definition}
    \hphantom{}

    Note that this means $\{\varnothing, \Omega\}$ is independent of anything else. \\

    Additionally, we say that a set $(X_{i})_{i \in I}$ of random variables is independent iff $(\sigma(X_{i}))_{i \in I}$ is independent. \\

    This definition requires a bit of work to deal with properly. One of the best general results we can attain quickly gives a fairly applicable result:
    \begin{theorem}
    \ With $(\Omega, \mathcal{F}, \mathbb{P})$ a probability space, $(\mathcal{A}_{i})_{i \in I}$ an arbitrary collection of $\pi$-systems, then $(\sigma(\mathcal{A}_{i}))_{i \in I}$ are independent iff for any finite $J \subseteq I$, $A_{i} \in \mathcal{A}_{i}$ for $i \in J$:
    \begin{align*}
      \mathbb{P}\left(\bigcap_{i \in J} A_{i}\right) &= \prod_{i \in J} \mathbb{P}(A_{i})
    \end{align*}
    \end{theorem}
    \hphantom{}

    We also have the result that for any independent set of $\sigma$-algebras, any subset is also independent. \\

    It takes a small bit of proving, but from the above results we get the lemma:
    \begin{lemma}
    \ With $(\Omega, \mathcal{F}, \mathbb{P})$, a family of independent random variables $X_{i} : \Omega \to E_{i}$, measurable functions $f_{i} : E_{i} \to \mathbb{R}$ for $i \in I$, then $(f(X_{i}))_{i \in I}$ are independent.
    \end{lemma}
    \hphantom{}

    \innerblock{Tail events}{
      \begin{definition}
        \ For a sequence of random variables $(X_{n})$, the tail $\sigma$-algebra is defined as
        \begin{align*}
          \mathcal{T} = \bigcap_{n = 1}^{\infty} \sigma(\{X_{k} : k > n\})
        \end{align*}

      \end{definition}
      \hphantom{}

      The intuition here is that all events in the tail $\sigma$-algebra contain sample information distinguishing the results of functions of infinitely many sequence elements. \\

      \begin{theorem}[Kolmogorov's 0-1 Law]
      \ Let $(X_{n})$ be a sequence of independent random variables. Then the tail $\sigma$-algebra of $(X_{n})$ contains only events with probability $0$ or $1$.
      \end{theorem}
      \hphantom{}

      To see this, we demonstrate that $\mathcal{T}$ is independent of a $\sigma$-algebra containing it, and therefore that all of its events are independent with themselves.
    }
    \hphantom{}

    \innerblock{Borel-Cantelli lemmas}{
      \begin{definition}
      \ With $(A_{n})$ a sequence of sets from $\mathcal{F}$:
      \begin{align*}
        \limsup_{n \to \infty} A_{n} &= \bigcap_{n=1}^{\infty} \bigcup_{m \ge n} A_{m} \\
                                     &= \{\omega \in \Omega : \omega \in A_{n} \text{ for infinitely many }n\} \\
                                     &= \{A_{n} \text{ infinitely often}\,\} \\
        \text{and} \quad \quad \liminf_{n \to \infty} A_{n} &= \bigcup_{n=1}^{\infty} \bigcap_{m \ge n} A_{m} \\
                                     &= \{\omega \in \Omega : \omega \in A_{n} \text{ eventually }\} \\
        &= \{ A_{n} \text{ eventually}\,\}
      \end{align*}
      \end{definition}
      \hphantom{}

      \begin{lemma}[Fatou and Reverse Fatou for sets]
      \ With $(A_{n})$ a sequence of sets in $\mathcal{F}$,
      \begin{align*}
        \mathbb{P}(\liminf_{n \to \infty} A_{n}) &\le \liminf_{n \to \infty} \mathbb{P}(A_{n}) \\
        \mathbb{P}(\limsup_{n\ \to \infty} A_{n}) &\ge \limsup_{n \to \infty} \mathbb{P}(A_{n}).
      \end{align*}
      \end{lemma}
      \hphantom{}

      \begin{lemma}[First Borel-Cantelli lemma]
        \ For $(A_{n})$ a sequence of events in $\mathcal{F}$, if
        \begin{align*}
          \sum_{n = 1}^{\infty} \mathbb{P}(A_{n}) < \infty,
        \end{align*}
        then $\mathbb{P}(A_{n} \text{ i.o.}) = 0$.
      \end{lemma}
      \hphantom{}

      \begin{lemma}[Second Borel-Cantelli lemma]
      \ For $(A_{n})$ a sequence of independent events in $\mathcal{F}$, if
      \begin{align*}
        \sum_{n=1}^{\infty} \mathbb{P}(A_{n}) = \infty,
      \end{align*}
      then $\mathbb{P}(A_{n} \text{ i.o.}) = 1$.
      \end{lemma}
      \hphantom{}

      By their nature, the BC lemmas are only informative in relation to almost sure events. While this may seem incredibly limited, by Kolmogorov's 0-1 Law, it turns out that many events of interest are in fact almost sure events.
    }
  }
  \column{0.2}
  \block{Integration}{
    As already covered in Part A Integration, we define integration as normal:

    \begin{definition}[Integral on simple functions]
    \ For a measure space $(\Omega, \mathcal{F}, \mu)$, $f : \Omega \to [0,\infty]$ a non-negative simple function taking values $\{a_{1},\dots,a_{n}\} \subseteq \mathbb{R}$:
    \begin{align*}
      \int f \, \mathrm{d}\mu &= \sum_{i=1}^{n} a_{i} \mu\left(f^{-1}\left(\{a_{i}\}\right)\right).
    \end{align*}
    \end{definition}
    \hphantom{}

    \begin{definition}[Integral on non-negative functions]
    \ For $f : \Omega \to [0,\infty]$ a non-negative measurable function:
    \begin{align*}
      \int f &= \sup \left\{\int g \,\mathrm{d}\mu : g \text{ simple },\, 0 \le g \le f \right\}
    \end{align*}
    \end{definition}
    \hphantom{}

    \begin{definition}[Integral]
      \ For $f : \Omega \to \mathbb{R}$ a measurable function and $\int |f| \, \mathrm{d}\mu < \infty$, we write $f^{+} = \max(f,0)$, $f^{-} = -\min(f,0)$, and
      \begin{align*}
        \int f \, \mathrm{d}\mu &= \int f^{+} \, \mathrm{d}\mu - \int f^{-} \, \mathrm{d}\mu
      \end{align*}
    \end{definition}
    \hphantom{}

    \begin{theorem}[Monotone convergence theorem]
      \ For $(f_{n})$ a sequence of non-negative functions measurable on $(\Omega, \mathcal{F}, \mu)$, such that $f_{n} \to f$ monotonically. Then
      \begin{align*}
        \int f_{n} \, \mathrm{d}\mu \to \int f \, \mathrm{d}\mu.
      \end{align*}
    \end{theorem}
    \hphantom{}

    \begin{theorem}[Fatou's lemma]
      \ For $(f_{n})$ a sequence of non-negative functions measurable on $(\Omega, \mathcal{F}, \mu)$,
      \begin{align*}
        \int \liminf_{n \to \infty} f_{n} \, \mathrm{d}\mu \le \liminf_{n \to \infty} \int f_{n} \, \mathrm{d}\mu
      \end{align*}
    \end{theorem}
    \hphantom{}

    \begin{lemma}[Reverse Fatou's lemma]
    \ For $(f_{n})$ a sequence of non-negative functions measurable on $(\Omega, \mathcal{F}, \mu)$, assume that there is an integrable function $g$ such that $f_{n} \le g$ for $n \ge 1$. Then
    \begin{align*}
      \int \limsup_{n \to \infty} f_{n} \, \mathrm{d}\mu \ge \limsup_{n \to \infty} \int f_{n} \, \mathrm{d}\mu
    \end{align*}
    \end{lemma}
    \hphantom{}

    \begin{theorem}[Dominated convergence theorem]
      \ For $(f_{n})$ a sequence of functions measurable on $(\Omega, \mathcal{F}, \mu)$ with $f_{n} \to f$ pointwise. Assume that there is an integrable function $g$ such that $|f_{n}| \le g$ for $n \ge 1$. Then
      \begin{align*}
        \int f_{n} \, \mathrm{d}\mu \to \int f \, \mathrm{d}\mu.
      \end{align*}
    \end{theorem}
    \hphantom{}

    \begin{theorem}
    \ Let $(\Omega, \mathcal{F}, \mathbb{P})$ be a probability space, $X : \Omega \to E$, $g : E \to \mathbb{R}$ measurable on their respective spaces. Then $g$ is $(\mathbb{P} \circ X^{-1})$-integrable iff $g \circ X$ is $\mathbb{P}$-integrable. Further,
    \begin{align*}
      \int_{E} g(x) \, \mathrm{d}(\mathbb{P} \circ X^{-1})(x) = \int_{\Omega} g(X(\omega)) \, \mathrm{d}\mathbb{P}(\omega).
    \end{align*}
    \end{theorem}
    \hphantom{}

    \begin{definition}[Expectation]
    \ For $X \in \mathcal{L}^{1}(\Omega, \mathcal{F}, \mathbb{P})$,
    \begin{align*}
      \mathbb{E}[X] = \int_{\Omega} X \, \mathrm{d}\mathbb{P}.
    \end{align*}
    \end{definition}
    \hphantom{}

    We say that $X$ admits an $n$th moment if $X \in \mathcal{L}^{n}(\Omega, \mathcal{F}, \mathbb{P})$. \\

    \begin{definition}[Variance]
    \ For $X \in \mathcal{L}^{2}(\Omega, \mathcal{F}, \mathbb{P})$,
    \begin{align*}
      \Var(X) = \mathbb{E}\left[(X-\mathbb{E}[X])^{2}\right].
    \end{align*}
    \end{definition}
    \hphantom{}

    \begin{definition}[Standardised moment]
    \ If $X \in \mathcal{L}^{n}(\Omega, \mathcal{F}, \mathbb{P})$, the $n$th standardised moment of $X$ is
    \begin{align*}
      \mathbb{E}\left[\left(\frac{X - \mathbb{E}[X]}{\sqrt{\Var(X)}}\right)^{n}\right]
    \end{align*}
    \end{definition}
    \hphantom{}

    \begin{theorem}[Fubini-Tonelli]
      \ Let $(\Omega, \mathcal{F}, \mathbb{P})$ be the product of probability spaces $(\Omega_{i}, \mathcal{F}_{i}, \mathbb{P}_{i})$ for $i \in \{1,2\}$, and $f : \Omega \to \mathbb{R}$ is a bounded measurable function. Then both
      \begin{align*}
        x &\mapsto \int_{\Omega_{2}} f(x,y) \, \mathrm{d}\mathbb{P}_{2}(y) \\
        \text{and } \quad y &\mapsto \int_{\Omega_{1}} f(x,y) \, \mathrm{d}\mathbb{P}_{1}(x)
      \end{align*}
      are measurable (respectively in $\mathcal{F}_{1}$ and $\mathcal{F}_2$). \\

      If either $f \ge 0$ or $f$ is $\mathbb{P}$-integrable over $\Omega$, then
      \begin{align*}
        \int_{\Omega} f \, \mathrm{d}\mathbb{P} = \int_{\Omega_{2}} \int_{\Omega_{1}} f(x,y) \, \mathrm{d}\mathbb{P}_{1}(x) \, \mathrm{d}\mathbb{P}_{2}(y) = \int_{\Omega_{1}} \int_{\Omega_{2}} f(x,y) \, \mathrm{d}\mathbb{P}_{2}(y) \, \mathrm{d}\mathbb{P}_{1}(x)
      \end{align*}

    \end{theorem}
    \hphantom{}

    \innerblock{Radon-Nikodym theorem}{
      Integration as we've defined it gives a canonical method of defining a measure on a space: as the integral of a fixed non-negative measurable function over the set being measured. \\

      Concretely: with a measure space $(\Omega, \mathcal{F}, \mu)$, a measurable function $f : \Omega \to [0,\infty]$, $A \in \mathcal{F}$,
      \begin{align*}
        \nu(A) := \int_{A} f \, \mathrm{d}\mu
      \end{align*}
      is a measure on $\mathcal{F}$ (via MCT). \\

      We therefore want to characterise how often a measure can be characterised in this way (in particular, whether we can get this the case with respect to $\mathrm{leb}$ or the counting measure, both for which we have a wealth of tools). \\

      \begin{theorem}[Radon-Nikodym theorem]
        \ Let $\mu$, $\nu$ be two probability measures on a $\sigma$-algebra $(\Omega, \mathcal{F})$. Then $\nu \ll \mu$ if and only if there is a measurable function $f : \Omega \to [0,\infty]$ such that for $A \in \mathcal{F}$,
        \begin{align*}
          \nu(A) = \int_{A} f\, \mathrm{d}\mu.
        \end{align*}
        Further, $\nu \sim \mu$ if and only if $\mu(f^{-1}(\{0\})) = \nu(f^{-1}(\{0\})) = 0$.
      \end{theorem}
      \hphantom{}

      We call $f$ the radon-nikodym derivative of $\nu$ with respect to $\mu$, $\displaystyle f = \frac{\mathrm{d}\nu}{\mathrm{d}\mu}$. If $\nu \sim \mu$, then $\displaystyle \frac{1}{f} = \frac{\mathrm{d}\mu}{\mathrm{d}\nu}$. \\

      This means that providing $\mathrm{leb}(A) = 0$ implies that $\nu(A) = 0$, we can construct $\nu$ in this way. \\

      Using this theorem, we can define for $A, B \in \mathcal{F}$ the conditional distribution $\mathbb{P}(A \,|\, B)$, provided $\mathbb{P}(B) > 0$. If $\mathbb{P}(A) = 0$, then $\displaystyle \frac{\mathbb{P}(A \cap B)}{\mathbb{P}(B)} = 0$, so there is some $f_{B} : \Omega \to [0,\infty]$ measurable such that
      \begin{align*}
        \frac{\mathbb{P}(A \cap B)}{\mathbb{P}(B)} &= \int_{A} f_{B}(\omega) \, \mathrm{d}\mathbb{P}(\omega).
      \end{align*}
    }
}

  \column{0.2}
  \block{Convergence}{
    We now consider modes of convergence of random variables using our results in integration. \\

    \begin{definition}[$\mathcal{L}^{p}$ spaces]
      \ For $p \ge 0$,
      \begin{align*}
        \mathcal{L}^{p}(\Omega, \mathcal{F}, \mathbb{P}) = \left\{X : \Omega \to \mathbb{R} \text{ measurable s.t. } \mathbb{E}\left[|X|^{p}\right] < \infty\right\}
      \end{align*}
      In particular, $\mathcal{L}^{0}$ is the space of all random variables, and $\mathcal{L}^{\infty}$ is the space of random variables which are bounded almost surely.
    \end{definition}
    \hphantom{}

    In these notes I'll refer almost exclusively to $\mathcal{L}^{p}$, although it's worth noting that there's a nuance here: the well-behaved space we generally want to refer to for useful results is not $\mathcal{L}^{p}$, but rather $L^{p} := \mathcal{L}^{p} / \mathcal{N}$, where $\mathcal{N} := \{X \in \mathcal{L}^{0} : \mathbb{E}\big[|X|\big] = 0\}$. At the same time, in this course it's not particularly desirable to be working with $X+\mathcal{N}$ constantly (not least because there are some instances where a property being `just' almost sure \emph{is} relevant), and therefore we principally use $\mathcal{L}^{p}$. \\

    An exception to the comments above comes for $0 \le p < 1$. $L^{p}$ for these values is almost entirely useless, as it is not a normed space. $\mathcal{L}^{p}$ \emph{does} have some use however, in particular for $p = 0$, in that it allows us to specify the set of measurable functions. \\

    \begin{definition}
    \ For a sequence $(X_{n})$ of random variables over $(\Omega, \mathcal{F}, \mathbb{P})$, we say that $X_{n}$ converges to $X$:
    \begin{enumerate}[label=\roman*.]
            \item almost surely ($X_{n} \overset{\mathrm{a.s.}}{\to} X$ or $X_{n} \to X$ a.s.) if
            \begin{align*}
              \mathbb{P}(X_{n} \to X \text{ as } n \to \infty) = 1.
            \end{align*}
            \item in probability ($X_{n} \overset{\mathbb{P}}{\to} X$) if for all $\varepsilon > 0$
            \begin{align*}
              \mathbb{P}(|X_{n}-X| > \varepsilon) \to 0
            \end{align*}
            as $n \to \infty$.
      \item in $\mathcal{L}^{p}$ ($X_{n} \overset{\mathcal{L}^{p}}{\to} X$) if $X_{n} \in \mathcal{L}^{p}$ for $n \ge 1$ and
          \begin{align*}
            \mathbb{E}[|X_{n}-X|^{p}] \to 0
          \end{align*}
            as $n \to \infty$.
      \item weakly in $\mathcal{L}^{1}$ if $X_{n} \in \mathcal{L}^{1}$ for $n \ge 1$ and for all $Y \in \mathcal{L}^{\infty}$
            \begin{align*}
              \mathbb{E}[X_{n}Y] \to \mathbb{E}[XY]
            \end{align*}
            as $n \to \infty$.
            \item in distribution ($X_{n} \overset{d}{\to} X$) if for $x \in \mathbb{R}$ such that $F_{X}$ is continuous,
            \begin{align*}
              F_{X_{n}}(x) \to F_{X}(x)
            \end{align*}
            as $n \to \infty$.
    \end{enumerate}
    \end{definition}
    \hphantom{}

    Of these, notion (v) of convergence in distribution is the odd one out, as it is independent of any particular instance of a random variable with the same distribution. This is a strictly weaker property than convergence in probability. \\

    Convergence in $\mathcal{L}^{p}$ is an identical notion to that in functional analysis, and (in a mathematical sense) leans very much into the measure-based notion of random variables. It is stronger both than weak convergence in $\mathcal{L}^{1}$ and convergence in probability. \\

    \begin{theorem}
      \ For a sequence $(X_{n})$ of random variables,
      \begin{enumerate}[label=\roman*.]
              \item If $X_{n} \overset{\mathrm{a.s.}}{\to} X$ then $X_{n} \overset{\mathbb{P}}{\to} X$.
              \item If $X_{n} \overset{\mathbb{P}}{\to} X$ then there is a subsequence $(X_{n_{k}})$ such that $X_{n_{k}} \overset{\mathrm{a.s.}}{\to} X$.
      \end{enumerate}
    \end{theorem}
    \hphantom{}

    \innerblock{Useful results}{
    \begin{lemma}[Markov's inequality]
    \ Let $(\Omega, \mathcal{F}, \mathbb{P})$ be a probability space, $X$ a non-negative random variable. Then for $\lambda > 0$,
    \begin{align*}
      \mathbb{P}(X \ge \lambda) \le \frac{\mathbb{E}[X]}{\lambda}
    \end{align*}
    \end{lemma}
    \hphantom{}

    \begin{corollary}[General Chebyshev's Inequality]
    \ For a measurable set $A \subseteq \mathbb{R}$, $X : \Omega \to A$ a random variable, $\varphi : A \to [0,\infty]$ an increasing measurable function. For $\lambda \in A$ with $\varphi(\lambda) < \infty$ we have
    \begin{align*}
      \mathbb{P}(X \ge \lambda) \le \frac{\mathbb{E}[\varphi(X)]}{\varphi(\lambda)}.
    \end{align*}
    \end{corollary}
    \hphantom{}

    This allows us to then demonstrate that for $p > 0$, $X_{n} \overset{\mathcal{L}^{p}}{\to} X$ implies $X_{n} \overset{\mathbb{P}}{\to} X$. \\

    Further, we can also show the weak law of large numbers:
    \begin{corollary}
    \ For $(X_{n})$ be a sequence of i.i.d. random variables with mean $\mu$, variance $\sigma^{2}$, then
    \begin{align*}
      \frac{1}{n}\sum_{k=1}^{n} X_{k} \to \mu
    \end{align*}
    as $n \to \infty$.
    \end{corollary}
    \hphantom{}

    \begin{theorem}[Jensen's inequality]
      \ Let $f : I \to \mathbb{R}$ be a convex function on an interval $I \subseteq \mathbb{R}$. If $X : \Omega \to I$ is an integrable random variable then
      \begin{align*}
        \mathbb{E}[f(X)] \ge f(\mathbb{E}[X]).
      \end{align*}
    \end{theorem}
    \hphantom{}
    }

    For considering the $\mathcal{L}^{p}$ spaces, we define $\Vert \cdot \Vert_{p} := \left(\mathbb{E}[|X|^{p}]\right)^{1/p}$. We can note immediately that for $0 \le p \le q$, $\mathcal{L}^{q} \subseteq \mathcal{L}^{p}$. \\

    Aside from this, note all the standard results regarding $\mathcal{L}^{p}$ spaces, in particular H\"{o}lder's inequality. A particular application of use is to note that for $1 < p, q < \infty$ with $1/p+1/q = 1$, and for $x > 0$,
    \begin{align*}
      x \mathbb{P}(X \ge x) \le \mathbb{E}[Y \chi_{X \ge x}],
    \end{align*}
    then $\Vert X \Vert_{p} \le q \Vert Y \Vert_{p}$. \\

    In $\mathcal{L}^{2}$, we are able to introduce some geometry to the space, defining an inner product $\langle X, Y \rangle := \mathbb{E}[XY]$. This allows us to consider $\mathcal{L}^{2}$ as a Hilbert space (modulus random variables equal to $0$ almost everywhere). Consequently we get all of the results that we normally have for Hilbert spaces within $\mathcal{L}^{2}$.
  }

  \block{Uniform Integrability}{
    We've now introduced the notions of convergence in $\mathcal{L}^{1}$, and seen that it implies convergence in probability. We'd quite like to go the other direction however, and find a sufficient condition for which the two are the same. \\

    \begin{definition}[Uniform integrability]
    \ A collection $\mathcal{C}$ of random variables is called uniformly integrable (UI) if
    \begin{align*}
      \lim_{N \to \infty} \sup_{X \in \mathcal{C}} \mathbb{E}[|X| \chi_{|X|>N}] = 0
    \end{align*}
    \end{definition}
    \hphantom{}

    Importantly, this is a property of collections, rather than individual random variables. The larger our collection is, the less likely it is to hold (and conversely, if $\mathcal{C}$ is UI, then $\mathcal{D} \subseteq \mathcal{C}$ is also UI). We can see immediately therefore that this is a property that can only hold for collections of random variables in $\mathcal{L}^{1}$, by considering the singleton sets which can be UI. \\

    If we have a $Y \in \mathcal{L}^{1}$ such that for $X \in \mathcal{C}$, $|X| \le Y$, then $\mathcal{C}$ is uniformly integrable. This is one of the most common methods for demonstrating a collection is UI. \\

    Another useful characterisation is found by reframing $|X|\chi_{|X| \ge N}$. From the below fact, we can see that we can replace it with $(|X|-N)^{+}$ in the definition of uniform integrability without effect:
    \begin{align*}
      0 \le (|X|-N)^{+} \le |X|\chi_{|X| \ge N} \le 2(|X|-N/2)^{+}.
    \end{align*}
    A common formulation that allows us to avoid having to determine the sets on which $|X| \ge N$ is given below:
    \begin{lemma}
      \ Let $\mathcal{C}$ be a family of random variables. Then $\mathcal{C}$ is UI iff $\displaystyle \sup_{X \in \mathcal{C}} \mathbb{E}\big[|X|\big] < \infty$ and
      \begin{align*}
        \sup \left\{\mathbb{E}\big[|X|\chi_{A}\big] : X \in \mathcal{C},\,A \in \mathcal{F},\, \mathbb{P}(A) \le \delta\right\} \to 0
      \end{align*}
      as $\delta \to 0$.
    \end{lemma}
    \hphantom{}

    \begin{theorem}[Vitali's convergence theorem]
    \ Take $(X_{n})$ a sequence of integrable random variables which converge in probability to a random variable $X$. The following are equivalent:
    \begin{enumerate}[label=\roman*.]
            \item $\{X_{n} : n \ge 1\}$ is uniformly integrable.
            \item $X \in \mathcal{L}^{1}$ and $\mathbb{E}\big[|X_{n}-X|\big] \to 0$ as $n \to \infty$.
            \item $X \in \mathcal{L}^{1}$ and $\mathbb{E}\big[|X_{n}|\big] \to \mathbb{E}\big[|X|\big]$ as $n \to \infty$.
    \end{enumerate}
    \end{theorem}
    \hphantom{}

    It's worth noting that (ii) is the definition of convergence in $\mathcal{L}^{1}$, from which we get (iii) just via the reverse triangle inequality. The difficult part of this proof is demonstrating that (iii) entails (i) which requires that characterisation of UI in terms of $(|X|-N)^{+}$ in conjunction with convergence in probability. \\

    By a non-examinable result (Dunford-Pettis), a collection is UI iff its closure is compact in $\sigma(L^{1},L^{\infty})$, which is the weak topology on $L^{1}$.
  }

  \column{0.2}
  \block{Filtrations}{
    \begin{definition}[Filtrations]
    \ For $(\Omega, \mathcal{F}, \mathbb{P})$ a probability space, a filtration $(\mathcal{F}_{n})$ is an sequence of $\sigma$-algebras ($\mathcal{F}_{n} \subseteq \mathcal{F}_{n+1}$ for $n \ge 1$). We then call $(\Omega, \mathcal{F}, (\mathcal{F}_{n}), \mathbb{P})$ a filtered probability space.
    \end{definition}
    \hphantom{}

    \begin{definition}[Adapted stochastic process]
    \ Take $(X_{n})$ a sequence of random variables, $(\mathcal{F}_{n})$ a filtration. If for $n \ge 1$, $X_{n}$ is $\mathcal{F}_{n}$ measurable, then $(X_{n})$ is said to be adapted to $(\mathcal{F}_{n})$.
    \end{definition}
    \hphantom{}

    Note that for a stochastic process $(X_{n})$, we get a natural filtration
    \begin{align*}
      \mathcal{F}_{n} := \sigma\left(\{X_{k} : k \le n\}\right).
    \end{align*}
    This is the smallest filtration possible. \\

    It's worth noting that with $\mathcal{F}_{\infty} = \bigcup_{n \ge 1} \mathcal{F}_{n}$, we don't necessarily have that $\mathcal{F}_{\infty} = \mathcal{F}$. Nonetheless, once we're working primarily within the filtered space, this shouldn't make a significant amount of difference, because the remainder of events will be inaccessible to any adapted process. \\

    \begin{definition}[Stopping time]
    \ Take $(\Omega, \mathcal{F}, (\mathcal{F}_{n}), \mathbb{P})$ a filtered probability space. A random variable $\tau : \Omega \to \mathbb{N} \cup \{\infty\}$ is a stopping time with respect to $(\mathcal{F}_{n})$ if for $n \ge 1$, $\tau^{-1}(\{n\}) \in \mathcal{F}_{n}$.
    \end{definition}
    \hphantom{}

    Immediate examples of stopping times can be given. Any constant is a stopping time, as are the maxima or minima of any two stopping times. Further, the first hitting time for an adapted stochastic process on any measurable set is a stopping time. \\

    \begin{definition}
    \ Let $\tau$ be a stopping time on $(\Omega, \mathcal{F}, (\mathcal{F}_{n}), \mathbb{P})$. The $\sigma$-algebra of information at time $\tau$ is
    \begin{align*}
      \mathcal{F}_{\tau} = \{A \in \mathcal{F}_{\infty} : \text{for } n \ge 1,\,A \cap \{\tau = n\} \in \mathcal{F}_{n}\}.
    \end{align*}
    \end{definition}

    This definition isn't entirely straightforward to understand, but the key aspect is this: if we have the value of $\tau$ (say we know that $\omega \in \{\tau = n\}$), then we shouldn't be able to infer from $\omega \in A \in \mathcal{F}_{\tau}$ that $\omega \in B \in \mathcal{F}_{\infty} \setminus \mathcal{F}_{n}$. The above definition should then be clear as containing the events which are possible to have observed by time $\tau$ (`time' being defined in accordance to steps in the filtration).\\

    We can then get our intuition that if for stopping times $\tau$ and $\rho$, $\tau \le \rho$, then $\mathcal{F}_{\tau} \subseteq \mathcal{F}_{\rho}$ (we get more information if we have longer to discover it). \\

    Note now that for $(X_{n})$ an adapted process, $\tau$ a stopping time, $X^{\tau} := (X_{\min(n,\tau)})$ is a `stopped process', and is adapted to both the filtration $(\mathcal{F}_{\min(n,\tau)})$ and hence $(\mathcal{F}_n)$. \\

    The filtration $(\mathcal{F}_{\min(n,\tau)})$ comes up often, and can be conceived essentially as the information given that you stop observing things (`exit the room') at time $\tau$, whenever that happens to be. This is what we mean by $\tau$ being a \emph{stopping} time, in that it stops the observations continuing.
  }
  \block{Martingales}{
    We often consider notions of random walks in probability theory. The most interesting of these are random walks where the movement at each step has expectation $0$, and this is a concept generalised by the notion of martingales. In this course we cover only the discrete case of martingales, although there is a rich theory concerning continuous martingales. \\

    \begin{definition}[Martingales]
      \ Let $(\Omega, \mathcal{F}, (\mathcal{F}_{n}), \mathbb{P})$ be a filtered probability space. An integrable, $(\mathcal{F}_{n})$-adapted stochastic process $(X_{n})$ is called
      \begin{enumerate}[label=\roman*.]
      \item a martingale if for $n \ge 0$, $\mathbb{E}\big[X_{n+1} \,|\, \mathcal{F}_{n}\big] = X_{n}$ a.s.;
      \item a submartingale if for $n \ge 0$, $\mathbb{E}\big[X_{n+1} \,|\, \mathcal{F}_{n}\big] \ge X_{n}$ a.s.; and
      \item a supermartingale if for $n \ge 0$, $\mathbb{E}\big[X_{n+1} \,|\, \mathcal{F}_{n}\big] \le X_{n}$ a.s..
      \end{enumerate}
    \end{definition}
    \hphantom{}

    We can note immediately that the difference between a super- and submartingale is almost purely aesthetic -- negate one and you get the other. Additionally, we can see that a sequence of random variables is a martingale iff it is both a super- and submartingale. Consequently, statements about submartingales are preferable for their generality to statements about martingales. \\

    Under this definition, the key property to observe for a submartingale $(X_{n})$ is this: for $m,n \ge 0$,
    \begin{align*}
      \mathbb{E}\big[X_{n} \,|\, \mathcal{F}_{m}\big] \ge X_{\min(m,n)},
    \end{align*}
    and the analogous relation follows for martingales and supermartingales. What this says is that a martingale is a sequence of random variables for which we expect no change on average. Meanwhile, a submartingale is a sequence which we expect to increase, and a supermartingale one we expect to decrease. To reflect this, we often refer to sequences $(Y_{n})$ satisfying $\mathbb{E}\big[Y_{n+1} \,|\, \mathcal{F}_{n}\big] = 0$ as `martingale difference sequences'. \\

    If a submartingale is adapted to a smaller filtration, then it is also a submartingale with respect to that filtration. This is because the only information a submartingale is using from the filtration is that in the natural filtration, and consequently the extra information is unnecessary. Note that this doesn't go the other direction though -- it's straightforward to construct a large filtration (e.g. the constant filtration $(\mathcal{F})$) such that $(X_{n})$ is not a submartingale, despite potentially being a martingale in a smaller filtration. \\

    A very general example of a martingale can be given just as a sum of independent random variables $(Y_{n})$ each with mean $0$, with respect to the natural filtration. Another cute example of a martingale involves taking an integrable random variable $X$ and an arbitrary filtration, then defining $X_{n} := \mathbb{E}\big[X \,|\, \mathcal{F}_{n}\big]$. \\

    \begin{lemma}
    \ Let $(X_{n})$ be a martingale with respect to $(\mathcal{F}_{n})$, and $f : \mathbb{R} \to \mathbb{R}$ convex. Then provided $(f(X_{n}))$ is a sequence of integrable random variables, then it is a submartingale.
    \end{lemma}
    \hphantom{}

    See this as an application of Jensen's inequality, and note that this has some very wide-reaching applications. \\

    \begin{definition}[Predictable process]
    \ A sequence $(V_{n})$ of random variables is predictable with respect to $(\mathcal{F}_{n})$ if $\sigma(V_{n}) \subseteq \mathcal{F}_{n-1}$ ($V_{n}$ is $\mathcal{F}_{n-1}$-measurable) for $n \ge 1$.
    \end{definition}
    \hphantom{}

    \begin{theorem}
    \ For $(\Omega, \mathcal{F}, (\mathcal{F}_{n}), \mathbb{P})$ a filtered probability space, $(Y_{n})$ a martingale, $(V_{n})$ a predictable process, both with respect to $(\mathcal{F}_{n})$, then defining for $n \ge 0$
    \begin{align*}
      X_{n} &= \sum_{k=1}^{n} V_{k}(Y_{k}-Y_{k-1}),
    \end{align*}
    if each $X_{n}$ is integrable then $(X_{n})$ is a martingale with respect to $(\mathcal{F}_{n})$.
    \end{theorem}
    \hphantom{}

    Note that the sequence $(X_{n})$ is a martingale transform, sometimes denoted $((V \circ Y)_{n})$. \\

    The definition of a submartingale prompts some questions about how exactly the sequence varies from being a martingale, and how exactly we might correct it back to a martingale. \\

    \begin{theorem}[Doob's Decomposition theorem]
    \ Let $(\Omega, \mathcal{F}, (\mathcal{F})_{n},\mathbb{P})$ be a filtered probability space, $(X_{n})$ an integrable adapted process.
    \begin{enumerate}[label=\roman*.]
            \item $(X_{n})$ has a Doob decomposition
            \begin{align*}
              X_{n} = X_{0} + M_{n} + A_{n}
            \end{align*}
            where $(M_{n})$ is a martingale, $(A_{n})$ is predictable with respect to $(\mathbb{F}_{n})$, and $M_{0} = A_{0} = 0$.
            \item For any $(\widetilde{M}_{n})$ a martingale, $(\widetilde{A}_{n})$ predictable such that $X_{n} = X_{0} + \widetilde{M}_{n} + \widetilde{A}_{n}$, $M_{n} = \widetilde{M}_{n}$ and $A_{n} = \widetilde{A}_{n}$ for all $n \ge 0$ almost surely.
            \item $(X_{n})$ is a sub(super)martingale iff $(A_{n})$ is non-decreasing (non-increasing) almost surely.
    \end{enumerate}
    \end{theorem}
    \hphantom{}

    An important consequence of this is known as the angle bracket process. For $(M_{n})$ a martingale of random variables in $\mathcal{L}^{2}$, we have that $(M_{n}^{2})$ is a submartingale. We write the Doob decomposition as
    \begin{align*}
      M_{n}^{2} = M_{0}^{2}+N_{n}+\langle M \rangle_{n}
    \end{align*}
    where $(N_{n})$ is a martingale, $(\langle M \rangle_{n})$ an increasing predictable process. Using predictability, we see that
    \begin{align*}
      \langle M \rangle_{n+1} - \langle M \rangle_{n} = \mathbb{E}\big[M_{n+1}^{2}-M_{n}^{2}\,|\, \mathcal{F}_{n}\big] = \mathbb{E}\big[(M_{n+1}-M_{n})^{2}\,|\,\mathcal{F}_{n}\big].
    \end{align*}
    This is the conditional variance of $(M_{n+1}-M_{n})$. \\

    \begin{theorem}
    \ Let $(\Omega, \mathcal{F}, (\mathcal{F}_{n}), \mathbb{P})$ be a filtered probability space, $(X_{n})$ a martingale, and $\tau$ a finite stopping time. Then $(X_{\min(n,\tau)})$ is a martingale with respect to $(\mathcal{F}_{n})$ and hence $(\mathcal{F}_{\min(n,\tau)})$.
    \end{theorem}
    \hphantom{}

    This can be proven by noting that $(\chi_{n \le \tau})$ is predictable, and thus we can write $(X_{\min(n,\tau)})$ in terms of both this and $(X_{n})$. \\

    \begin{theorem}[Doob's Optional Sampling theorem]
      \ Let $(\Omega, \mathcal{F}, (\mathcal{F}_{n}), \mathbb{P})$ be a filtered probability space, $(X_{n})$ a martingale, and $\tau,\,\rho$ two finite stopping times, $\tau \le \rho$. Then
      \begin{align*}
        \mathbb{E}\big[X_{\rho} \,|\, \mathcal{F}_{\tau}\big] \overset{\mathrm{a.s.}}{=} X_{\tau},
      \end{align*}
      and in particular, $\mathbb{E}\big[X_{\rho}\big] = \mathbb{E}\big[X_{\tau}\big] = \mathbb{E}\big[X_{0}\big]$. \\

      Similarly, if $(X_{n})$ is a submartingale, then $\mathbb{E}\big[X_{\rho}\,|\, \mathcal{F}_{\tau}\big] \ge X_{\tau}$ a.s..
    \end{theorem}
    \hphantom{}

    We can prove this in two steps. Firstly, prove the case for $\rho$ constant, and then consider the martingale $(X_{\min(n,\rho)}-X_{\min(n,\tau)})$ stopped at $\tau$. \\

    This theorem is quite an important one, as we essentially just expand the definition of a martingale (and, via decomposition, super- and submartingales). The intuition should be that if $(X_{n})$ is a process stopping at $\rho$, but we only observe it up to $\tau$, the properties of the martingale should allow us to calculate the expected value of $X_{\rho}$ as $X_{\tau}$. Importantly, we also generalise that a martingale's expectation is constant, even if stopping at a random time (as long as the time is bounded). \\

    We can also get a generalisation beyond just bounded stopping times:
    \begin{corollary}
      \ Let $(X_{n})$ be a martingale, $\tau$ an a.s. finite stopping time. If either $\{X_{n} : n \ge 0\}$ is UI, or $\mathbb{E}\big[\tau\big] < \infty$ and the sequence $\displaystyle        \left(\mathbb{E}\big[|X_{n+1}-X_{n}| \,\big|\, \mathcal{F}_{n}\big]\right)$ is bounded, then
      \begin{align*}
        \mathbb{E}\big[X_{\tau} \chi_{\tau < \infty}\big] = \mathbb{E}\big[X_{0}\big].
      \end{align*}
    \end{corollary}

    We would like to keep characterising martingales further -- in particular wishing to bound them.
    \begin{theorem}[Doob's maximal inequality]
      \ Let $(X_{n})$ be a submartingale. Then, for $\lambda > 0$,
      \begin{align*}
        Y^{\lambda}_{n} := (X_{n}-\lambda)\chi_{\bigcup_{k=1}^{n} \{X_{k} \ge \lambda\}}
      \end{align*}
      is a submartingale, and for $n \ge 1$,
      \begin{align*}
        \lambda \mathbb{P}\left(\bigcup_{k=1}^{n} \{X_{k} \ge \lambda\}\right) \le \mathbb{E}\big[X_{n} \chi_{\bigcup_{k=1}^{n} \{X_{k} \ge \lambda\}}\big] \le \mathbb{E}\big[|X_{n}|\big].
      \end{align*}
    \end{theorem}

    Essentially, we expect $(X_{n})$ to grow, but only so quickly. This should (I think?) follow from considering the hitting time of $\rightopen{\lambda}{\infty}$. We then get that if $(X_{n})$ is a martingale in $\mathcal{L}^{p}$,
    \begin{align*}
      \mathbb{P}\left(\bigcup_{k = 1}^{n} \{|X_{k}| \ge \lambda \}\right) \le \frac{\mathbb{E}\big[|X_{n}|^{p}\big]}{\lambda^{p}}.
    \end{align*}
    \begin{theorem}[Doob's $\mathcal{L}^{p}$ inequality]
      \ Let $(X_{n})$ be a non-negative submartingale in $\mathcal{L}^{p}$ for $p \ge 1$. Then $\displaystyle \max_{k \le n} X_{k} \in \mathcal{L}^{p}$ and
      \begin{align*}
        \mathbb{E}\big[X^{p}_{n}\big] \le \mathbb{E}\left[\max_{k \le n} X_{k}^{p}\right] \le \left(\frac{p}{p-1}\right)^{p}\mathbb{E}\big[X^{p}_{n}\big].
      \end{align*}
    \end{theorem}
    \hphantom{}

  }
\end{columns}

\end{document}
